{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39f058d4-461e-43ba-93b2-30855be1896b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "initialize"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"DateTransformation\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdb3c6fc-1bd4-441b-80af-831c4c749ff5",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1753479044104}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "define udf"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DecimalType, StringType, StructField, StructType\n",
    "from \n",
    "import re\n",
    "\n",
    "# Define the schema for the returned STRUCT type\n",
    "measure_unit_schema = StructType([\n",
    "    StructField(\"Measure\", StringType(), True),\n",
    "    StructField(\"UnitOfMeasure\", StringType(), True),\n",
    "    StructField(\"PackageUnits\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Register the UDFs\n",
    "infer_and_transform_date_udf = udf(infer_and_transform_date, StringType())\n",
    "transform_price_udf = udf(transform_price, DecimalType())\n",
    "remove_special_characters_udf = udf(remove_special_characters, StringType())\n",
    "separate_camel_case_udf = udf(separate_camel_case, StringType())\n",
    "transform_provider_name_udf = udf(transform_provider_name, StringType())\n",
    "extract_measure_and_unit_udf = udf(extract_measure_and_unit, measure_unit_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9170139e-fc00-451d-aa70-5c3455da081a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "read table"
    }
   },
   "outputs": [],
   "source": [
    "# Read the table into a DataFrame\n",
    "df = spark.read.table(\"workspace.default.products_from_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d27787db-abb0-4322-94ec-6c080a9c8448",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "transform"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, initcap, when\n",
    "\n",
    "# Convert data types using the UDFs\n",
    "df = df.withColumn(\"RawPrice\", col(\"Price\")) \\\n",
    "       .withColumn(\"CleanPrice\", transform_price_udf(col(\"Price\"))) \\\n",
    "       .withColumn(\"RawLastReviewDt\", col(\"LastReviewDt\")) \\\n",
    "       .withColumn(\"CleanLastReviewDt\", infer_and_transform_date_udf(col(\"LastReviewDt\"))) \\\n",
    "       .withColumn(\"RawDescription\", col(\"Description\")) \\\n",
    "       .withColumn(\"CleanDescription\", remove_special_characters_udf(col(\"Description\"))) \\\n",
    "       .withColumn(\"CleanProviderName\", initcap(transform_provider_name_udf(col(\"ProviderName\")))) \\\n",
    "       .withColumn(\"IsValidPrice\", when(col(\"Price\").isNull(), False).otherwise(True))\n",
    "\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c027869-a98b-4555-abff-7df81c05df15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "\n",
    "# Convert data types using the UDFs\n",
    "df = df.withColumn(\"MeasureUnit\", extract_measure_and_unit_udf(col(\"Description\"))) \\\n",
    "       .withColumn(\"Measure\", col(\"MeasureUnit.Measure\")) \\\n",
    "       .withColumn(\"UnitOfMeasure\", col(\"MeasureUnit.UnitOfMeasure\")) \\\n",
    "       .withColumn(\"PackageUnits\", col(\"MeasureUnit.PackageUnits\")) \\\n",
    "       .withColumn(\"UnitOfMeasure\", lower(col(\"UnitOfMeasure\")))\n",
    "\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "738857f1-ce02-428c-bcee-9ad5b5b48501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Contexto: \n",
    "    * Eres un API que recibirá descripciones breves de productos, principalmente en español. Estos productos provienen de catálogos de diferentes provedores y sus descripciones no son consistentes en cuanto al uso de preposiciones, abreviaciones, unidades de medida, cantidad por unidad y unidades por paquete. Por tanto, trata de extraer esta información, además del nombre correcto del producto para evitar dichas ambiguedades del provedor. \n",
    "\n",
    "    Reglas:\n",
    "    * Si el nombre del producto contiene palabras en ingles y estas tienen algún error ortográfico, corrigelo pero nunca traduzcas. \n",
    "    * Nunca omitas palabras presentes en el nombre del producto. \n",
    "    * Si no tienes certeza, un humano debe revisar el nombre. \n",
    "    * Si la descripción del producto contiene la unidad de medida, cambila por su abbreviación.\n",
    "    * Debe inferir el nombre del producto, la unidad de medida, la medida según la unidad de medida y la cantidad de unidades por paquete (algunos provedores venden por paquetes y no por unidades).\n",
    "    * Si los valores de las propiedades numéricas no son claros, use 1 por defecto. \n",
    "    * Si el producto no especifica la unidad de medida, intente inferirla segun el tipo de producto. Por ejemplo, si el producto es una 'Coca Cola pequeña', la unidad de medida sería 'ml' de mililitros, y si la Coca Cola es grande, la unidad de medida sería 'l' de litros. \n",
    "    * Si no se puede saber cual es la unidad de medida, utilize 'u' que significa 'unidad' y funciona como fallback. \n",
    "    * Si un humando debe revisar el nombre del producto, 'needsHumanVerification' debe ser true. \n",
    "    * 'B' significa 'Barato', asi que cambialo si aparece en la descripción del producto.\n",
    "\n",
    "    Formato de la respuesta:\n",
    "    * Su respuesta será un objeto JSON con las propiedades 'productName', 'unitType', 'units', 'packageUnits' y 'needsHumanVerification'. \n",
    "    * Si se tiene certeza, y no necesitas que un humano revise, el objeto JSON no debe contener la propieded 'needsHumanVerification'.\n",
    "    * El 'productName' es del tipo string.\n",
    "    * El 'unitType' es del tipo string y debe abreviarse en español y en minúsculas. \n",
    "    * El 'units' es un número decimal\n",
    "    * El 'packageUnits' siempre es un número entero\n",
    "    * RESPONDE UNICAMENTE EL JSON OBJECT, NO EXPLICACION, NO PREFIJOS, NADA MAS\n",
    "    \n",
    "    Esta es la descripción del producto: \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e59073e4-9b18-40e7-806a-78a0618229fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"products_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2e32f28-c079-40c6-b098-2d071df5a843",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Escape single quotes and replace newlines in the prompt\n",
    "prompt_sql = prompt.replace(\"'\", \"''\").replace(\"\\n\", \" \")\n",
    "\n",
    "df_out = df.selectExpr(f\"ai_query('databricks-meta-llama-3-3-70b-instruct', CONCAT('{prompt_sql}', Description), modelParameters => named_struct('max_tokens', 100, 'temperature', 0.5)) as summary\"\n",
    ").limit(10)\n",
    "\n",
    "display(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e52a8526-2ebb-4dd3-97fe-bcc901c44cc6",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1753576809997}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "clean-date-notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
